{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr3NILuMckat"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.models import densenet121\n",
        "from torchvision.models import alexnet\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TYuGdFQclWq",
        "outputId": "440a0f58-262d-4e8e-f3e2-7553e5fd903b"
      },
      "outputs": [],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/violence-detection')\n",
        "from convlstm import ConvLSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd7v5VXOckaw"
      },
      "outputs": [],
      "source": [
        "# Train data directory\n",
        "directory = '/content/drive/MyDrive/data' #modify as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1wLkt5Cckaw"
      },
      "outputs": [],
      "source": [
        "# # TESTING THAT A VIDEO CAN BE READ\n",
        "# # Create a VideoCapture object\n",
        "# cap = cv2.VideoCapture(directory + '/' + 'Violence' + '/' + 'Violence001.avi')\n",
        "\n",
        "# # Check if camera opened successfully\n",
        "# if (cap.isOpened()== False):\n",
        "#     print(\"Error opening video file\")\n",
        "\n",
        "# # Read until video is completed\n",
        "# while(cap.isOpened()):\n",
        "#     # Capture frame-by-frame\n",
        "#     ret, frame = cap.read()\n",
        "#     if ret == True:\n",
        "#         # Display the resulting frame\n",
        "#         cv2.imshow('Frame', frame)\n",
        "#         # Press Q on keyboard to exit\n",
        "#         if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "#             break\n",
        "#     # Break the loop\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "# # When everything done, release the video capture object\n",
        "# cap.release()\n",
        "\n",
        "# # Closes all the frames\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRh3M_Sockax"
      },
      "outputs": [],
      "source": [
        "def calculate_optical_flow(video_path, frame_skip=4):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame1 = cap.read()\n",
        "    prvs = cv2.resize(frame1, (224, 224))\n",
        "    prvs = cv2.cvtColor(prvs, cv2.COLOR_BGR2GRAY)\n",
        "    hsv = np.zeros((prvs.shape[0], prvs.shape[1], 3))\n",
        "    hsv[..., 1] = 255\n",
        "\n",
        "    optical_flows = []  # list to store optical flow of each frame\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame2 = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_count += 1\n",
        "        if frame_count % frame_skip != 0:\n",
        "            continue\n",
        "        next = cv2.resize(frame2, (224, 224))\n",
        "        next = cv2.cvtColor(next, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        flow = cv2.calcOpticalFlowFarneback(\n",
        "            prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        bgr = cv2.cvtColor(hsv.astype(np.float32), cv2.COLOR_HSV2BGR)\n",
        "        # normalize\n",
        "        # bgr = (bgr - bgr.min()) / (bgr.max() - bgr.min())\n",
        "        optical_flows.append(bgr)  # store optical flow of current frame\n",
        "\n",
        "        prvs = next\n",
        "\n",
        "    cap.release()\n",
        "    return optical_flows  # return list of optical flows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7eIUJk-ckay"
      },
      "source": [
        "### Loading all videos, transforming them into optical flow representations, storing in memory, and creating a training/testing data loader.\n",
        "\n",
        "**Now the model is ready to be trained**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYT3sgQ9BdQK",
        "outputId": "fdd452c2-0a64-4789-8284-5f63606839b7"
      },
      "outputs": [],
      "source": [
        "Videos = []\n",
        "labels = []\n",
        "\n",
        "for filename in tqdm(os.listdir(directory)):\n",
        "    if filename.endswith(\".avi\"):  # videos are in .avi format\n",
        "        video_path = os.path.join(directory, filename)\n",
        "        # assuming this now returns a list of optical flows\n",
        "        frame_skip = 2\n",
        "        resultant_frames = 20\n",
        "        optical_flows = calculate_optical_flow(video_path, frame_skip = frame_skip)\n",
        "        if len(optical_flows) < resultant_frames:\n",
        "          padding = [np.zeros_like(optical_flows[0]) for _ in range(resultant_frames - len(optical_flows))]\n",
        "          optical_flows = padding + optical_flows\n",
        "        elif len(optical_flows) > resultant_frames:\n",
        "          optical_flows = optical_flows[:resultant_frames]\n",
        "        # transpose each optical flow\n",
        "        optical_flows = np.stack(\n",
        "            [np.transpose(flow, (2, 0, 1)) for flow in optical_flows])\n",
        "        if filename.startswith('fi'):\n",
        "            Videos.append(optical_flows)\n",
        "            labels.append(0)\n",
        "        elif filename.startswith('no'):\n",
        "            Videos.append(optical_flows)\n",
        "            labels.append(1)\n",
        "\n",
        "data = np.array(Videos, dtype=np.float32)\n",
        "labels = np.array(labels, dtype=np.int64)\n",
        "\n",
        "# split into train ad test data using sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# train data\n",
        "# train_data = torch.tensor(train_data).half()\n",
        "train_data = torch.tensor(train_data)\n",
        "train_data = train_data.permute(0, 2, 1, 3, 4)\n",
        "# print(train_data.shape)\n",
        "\n",
        "train_labels = torch.tensor(train_labels).long()\n",
        "train_dataset = TensorDataset(train_data, train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "print(len(train_loader))\n",
        "print(train_loader.dataset.tensors[0].shape)\n",
        "\n",
        "# test data\n",
        "# test_data = torch.tensor(test_data).half()\n",
        "test_data = torch.tensor(test_data)\n",
        "test_data = test_data.permute(0, 2, 1, 3, 4)\n",
        "\n",
        "# print(test_data.shape)\n",
        "test_labels = torch.tensor(test_labels).long()\n",
        "test_dataset = TensorDataset(test_data, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "print(len(test_loader))\n",
        "print(test_loader.dataset.tensors[0].shape)\n",
        "# Save\n",
        "torch.save(train_loader, '/content/drive/My Drive/train_loader.pth')\n",
        "torch.save(test_loader, '/content/drive/My Drive/test_loader.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run the cell below if you already have the loaders saved**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRmk8_ktvEOe"
      },
      "outputs": [],
      "source": [
        "# train_loader = torch.load('/content/drive/My Drive/train_loader.pth')\n",
        "# test_loader = torch.load('/content/drive/My Drive/test_loader.pth')\n",
        "# print(len(train_loader))\n",
        "# print(len(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2vOplvpcka0"
      },
      "source": [
        "### DenseNet121 model adapted for video data and ConvLSTM added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QhwxVzRm2-n",
        "outputId": "66621c00-9624-49ad-c13d-cfa3cd7dd911"
      },
      "outputs": [],
      "source": [
        "model = densenet121(pretrained=True)\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2zx0nVfvv7L"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super().__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm3d(num_input_features))\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
        "        self.add_module(\n",
        "            'conv1',\n",
        "            nn.Conv3d(num_input_features,\n",
        "                      bn_size * growth_rate,\n",
        "                      kernel_size=1,\n",
        "                      stride=1,\n",
        "                      bias=False))\n",
        "        self.add_module('norm2', nn.BatchNorm3d(bn_size * growth_rate))\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
        "        self.add_module(\n",
        "            'conv2',\n",
        "            nn.Conv3d(bn_size * growth_rate,\n",
        "                      growth_rate,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1,\n",
        "                      bias=False))\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super().forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features,\n",
        "                                     p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate,\n",
        "                 drop_rate):\n",
        "        super().__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate,\n",
        "                                growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer{}'.format(i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super().__init__()\n",
        "        self.add_module('norm', nn.BatchNorm3d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module(\n",
        "            'conv',\n",
        "            nn.Conv3d(num_input_features,\n",
        "                      num_output_features,\n",
        "                      kernel_size=1,\n",
        "                      stride=1,\n",
        "                      bias=False))\n",
        "        self.add_module('pool', nn.AvgPool3d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    \"\"\"Densenet-BC model class\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (k in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_input_channels=3,\n",
        "                 conv1_t_size=7,\n",
        "                 conv1_t_stride=1,\n",
        "                 no_max_pool=False,\n",
        "                 growth_rate=32,\n",
        "                 block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64,\n",
        "                 bn_size=4,\n",
        "                 drop_rate=0,\n",
        "                 num_classes=2):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = [('conv1',\n",
        "                          nn.Conv3d(n_input_channels,\n",
        "                                    num_init_features,\n",
        "                                    kernel_size=(conv1_t_size, 7, 7),\n",
        "                                    stride=(conv1_t_stride, 2, 2),\n",
        "                                    padding=(conv1_t_size // 2, 3, 3),\n",
        "                                    bias=False)),\n",
        "                         ('norm1', nn.BatchNorm3d(num_init_features)),\n",
        "                         ('relu1', nn.ReLU(inplace=True))]\n",
        "        if not no_max_pool:\n",
        "            self.features.append(\n",
        "                ('pool1', nn.MaxPool3d(kernel_size=3, stride=2, padding=1)))\n",
        "        self.features = nn.Sequential(OrderedDict(self.features))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers,\n",
        "                                num_input_features=num_features,\n",
        "                                bn_size=bn_size,\n",
        "                                growth_rate=growth_rate,\n",
        "                                drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock{}'.format(i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition{}'.format(i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "\n",
        "        self.add_module('convlstm', ConvLSTM(input_dim=1,\n",
        "                                                      hidden_dim=[4, 4],\n",
        "                                                      kernel_size=(3, 3),\n",
        "                                                      num_layers=2,\n",
        "                                                      batch_first=True,\n",
        "                                                      bias=True,\n",
        "                                                      return_all_layers=False))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            elif isinstance(m, nn.BatchNorm3d) or isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(196, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(m.weight,\n",
        "                                        mode='fan_out',\n",
        "                                        nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        # print(features.shape)\n",
        "        out,_ = self.convlstm(features)\n",
        "        # Take the output from the last time step of the LSTM\n",
        "        out = out[0][:, -1, :, :, :]  # Shape: [batch, channels, height, width]\n",
        "\n",
        "        flattened_output = out.view(out.size(0), -1)  # Shape: [batch, channels*height*width]\n",
        "\n",
        "        # print(flattened_output.shape)\n",
        "        classified_output = self.classifier(flattened_output)\n",
        "\n",
        "        return classified_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQd6nPrAs3le",
        "outputId": "f461c09f-6c8c-40a5-b03c-1d7c01c8e915"
      },
      "outputs": [],
      "source": [
        "model = DenseNet(num_init_features=32,\n",
        "                         growth_rate=16,\n",
        "                         block_config=(6, 12, 24, 16))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W592IYmIqGz_",
        "outputId": "55760885-f84c-485d-f0d3-db2cd442c331"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm91DWbNcka1"
      },
      "source": [
        "**The cell below tests that the model is working as expected**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5gmo2xlcka2",
        "outputId": "bfe72dbc-ce42-4e41-d4e4-dbb16967ef31"
      },
      "outputs": [],
      "source": [
        "# Test model on one optical flow example\n",
        "# test_vid_path = directory + '/' + 'Violence' + '/' + 'Violence001.avi'\n",
        "test_vid_path = directory + '/' + 'fi1_xvid.avi'\n",
        "test_optical_flow = calculate_optical_flow(test_vid_path, 2)\n",
        "# assuming this now returns a list of optical flows\n",
        "test_optical_flow = np.stack([np.transpose(flow, (2, 0, 1))\n",
        "                             for flow in test_optical_flow])\n",
        "# test_optical_flow = torch.tensor(test_optical_flow).half().unsqueeze(0)\n",
        "test_optical_flow = torch.tensor(test_optical_flow).unsqueeze(0)\n",
        "test_optical_flow = test_optical_flow.permute(0, 2, 1, 3, 4)\n",
        "test_optical_flow = test_optical_flow.to(device)\n",
        "print(test_optical_flow.shape)\n",
        "torch.cuda.empty_cache()\n",
        "output = model(test_optical_flow)\n",
        "print(output.shape) # [1, 2]\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaF0x504cka2"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot37UrSncka3",
        "outputId": "74cba0e8-b22e-4889-a87e-805062f1459e"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
        "lossfun = nn.CrossEntropyLoss()\n",
        "# number of epochs\n",
        "numepochs = 50\n",
        "# create a new model\n",
        "# initialize losses\n",
        "losses = []\n",
        "trainAcc = []\n",
        "testAcc = []\n",
        "# loop over epochs\n",
        "for epochi in range(numepochs):\n",
        "  torch.cuda.empty_cache() # clear cache\n",
        "  # switch on training mode\n",
        "  model.train()\n",
        "\n",
        "  # loop over training data batches\n",
        "  batchAcc = []\n",
        "  batchLoss = []\n",
        "  for X, y in train_loader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    # forward pass and loss\n",
        "    yHat = model(X)\n",
        "    # print(yHat.isnan().any())\n",
        "    loss = lossfun(yHat, y)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(loss.item())\n",
        "    # loss from this batch\n",
        "    batchLoss.append(loss.item())\n",
        "    # compute accuracy\n",
        "    batchAcc.append(\n",
        "        100*torch.mean((torch.argmax(yHat, axis=1) == y).float()).item())\n",
        "    torch.cuda.empty_cache()\n",
        "  # end of batch loop...\n",
        "  # now that we've trained through the batches, get their average training accuracy\n",
        "  trainAcc.append(np.mean(batchAcc))\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    batchAcc = []\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        batchAcc.append(100*torch.mean((torch.argmax(outputs, axis=1) == labels).float()).item())\n",
        "        yTrue.extend(labels.cpu().numpy())\n",
        "        yPred.extend(torch.argmax(outputs, axis=1).cpu().numpy())\n",
        "    testAcc.append(np.mean(batchAcc))\n",
        "    if testAcc[-1] >= 80:\n",
        "      break\n",
        "  # end of epoch loop...\n",
        "\n",
        "\n",
        "  # and get average losses across the batches\n",
        "  losses.append(np.mean(batchLoss))\n",
        "\n",
        "  print(\n",
        "      f'Epoch {epochi+1}/{numepochs}, Loss: {losses[-1]}, Train Accuracy: {trainAcc[-1]}, Test Accuracy: {testAcc[-1]}')\n",
        "# end epochs\n",
        "# output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn4elbSNcka3"
      },
      "outputs": [],
      "source": [
        "# # Save the model\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1WcRHimcka4"
      },
      "source": [
        "## Testing Model Performance\n",
        "**If model has been trained (or trained and the model is saved in a pth file), run the cells below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-1a8vG1cka5"
      },
      "outputs": [],
      "source": [
        "# # Uncomment this cell only if you have the saved model and wish to load it. Note: model variable must be initialized above before loading the model\n",
        "# def getSavedModel():\n",
        "#     model.load_state_dict(torch.load('model.pth'))\n",
        "#     return model\n",
        "# model = getSavedModel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "260DnkxVcka5"
      },
      "source": [
        "**Get predictions using test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "NCJijHIEcka6",
        "outputId": "d72982be-5c28-48de-f3ac-ff0a02a8fe7e"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "testAcc2 = []\n",
        "with torch.no_grad():\n",
        "    yTrue = []\n",
        "    yPred = []\n",
        "    batchAcc = []\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        batchAcc.append(100*torch.mean((torch.argmax(outputs, axis=1) == labels).float()).item())\n",
        "        yTrue.extend(labels.cpu().numpy())\n",
        "        yPred.extend(torch.argmax(outputs, axis=1).cpu().numpy())\n",
        "    testAcc2.append(np.mean(batchAcc))\n",
        "print(classification_report(yTrue, yPred))\n",
        "print('Accuracy:', accuracy_score(yTrue, yPred))\n",
        "print('F1:', f1_score(yTrue, yPred, average='weighted'))\n",
        "print('Precision:', precision_score(yTrue, yPred, average='weighted'))\n",
        "print('Recall:', recall_score(yTrue, yPred, average='weighted'))\n",
        "sns.heatmap(confusion_matrix(yTrue, yPred), annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Violence', 'Normal'], yticklabels=['Violence', 'Normal'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kha3r6wAcka7"
      },
      "source": [
        "**Do not run the cell below if you did not train the model prior**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1yYF1Jd8cka7",
        "outputId": "f3f1e4b7-1feb-4125-c261-ceee7608ec10"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN THIS CELL IF YOU LOADED THE MODEL AND DID NOT TRAIN IT AS TRAINACC & LOSSES WILL BE UNDEFINED\n",
        "# Plot trainAcc and losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(trainAcc)\n",
        "plt.plot(testAcc)\n",
        "plt.title('Training vs Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend(['Training', 'Testing'])\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ZKAC3RHYeG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
